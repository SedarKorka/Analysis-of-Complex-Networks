{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FullName : Diallo Mamadou Korka\n",
      "Studend’s Number: 022028845F\n",
      "      \n",
      "Modelling and Analysis of Complex Networks\n",
      "Assignment : 9 \n",
      "Number of the dataset : 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "FullName : Diallo Mamadou Korka\n",
    "Studend’s Number: 022028845F\n",
    "      \n",
    "Modelling and Analysis of Complex Networks\n",
    "Assignment : 9 \n",
    "Number of the dataset : 3\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the modules\n",
    "import urllib.request\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, roc_curve\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset\n",
    "# Load the Facebook-Ego network\n",
    "facebook_url = \"https://raw.githubusercontent.com/wang422003/Complex-Networks_exercise/main/Datasets/Group3/Facebook-Ego/348.edges\"\n",
    "urllib.request.urlretrieve(facebook_url, \"facebook.edges\")\n",
    "facebook_network = nx.read_edgelist(\"facebook.edges\", nodetype=int)\n",
    "\n",
    "# Load the Twitter-Ego network\n",
    "twitter_url = \"https://raw.githubusercontent.com/wang422003/Complex-Networks_exercise/main/Datasets/Group3/Twitter-Ego/789071.edges\"\n",
    "urllib.request.urlretrieve(twitter_url, \"twitter.edges\")\n",
    "twitter_network = nx.read_edgelist(\"twitter.edges\", nodetype=int, create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the graph to an adjacency matrix\n",
    "adjacency_matrix = nx.to_numpy_matrix(facebook_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random labels (0 or 1) for the edges\n",
    "labels = np.random.choice([0, 1], size=(facebook_network.number_of_nodes(), facebook_network.number_of_nodes()))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(adjacency_matrix, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model\n",
    "class LinkPredictionModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LinkPredictionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "input_size = adjacency_matrix.shape[1]\n",
    "hidden_size = 64\n",
    "output_size = 1  # Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinkPredictionModel(input_size, hidden_size, output_size)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Size mismatch between tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/Analysis-of-Complex-Networks/ass9.ipynb Cell 9\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bbookish-space-succotash-5rq5pqg9rwv3797v/workspaces/Analysis-of-Complex-Networks/ass9.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m y_train_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mFloatTensor(y_train\u001b[39m.\u001b[39mflatten())\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bbookish-space-succotash-5rq5pqg9rwv3797v/workspaces/Analysis-of-Complex-Networks/ass9.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Create a TensorDataset\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bbookish-space-succotash-5rq5pqg9rwv3797v/workspaces/Analysis-of-Complex-Networks/ass9.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m dataset \u001b[39m=\u001b[39m TensorDataset(X_train_tensor, y_train_tensor)\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bbookish-space-succotash-5rq5pqg9rwv3797v/workspaces/Analysis-of-Complex-Networks/ass9.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Create a DataLoader\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bbookish-space-succotash-5rq5pqg9rwv3797v/workspaces/Analysis-of-Complex-Networks/ass9.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m32\u001b[39m  \u001b[39m# You can adjust this based on your dataset size\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataset.py:204\u001b[0m, in \u001b[0;36mTensorDataset.__init__\u001b[0;34m(self, *tensors)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39mtensors: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 204\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39m(tensors[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39m==\u001b[39m tensor\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39mfor\u001b[39;00m tensor \u001b[39min\u001b[39;00m tensors), \u001b[39m\"\u001b[39m\u001b[39mSize mismatch between tensors\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    205\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtensors \u001b[39m=\u001b[39m tensors\n",
      "\u001b[0;31mAssertionError\u001b[0m: Size mismatch between tensors"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.FloatTensor(y_train.flatten())\n",
    "\n",
    "# Create a TensorDataset\n",
    "dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "\n",
    "# Create a DataLoader\n",
    "batch_size = 32  # You can adjust this based on your dataset size\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_inputs, batch_labels in dataloader:\n",
    "        # Forward pass\n",
    "        outputs = model(batch_inputs)\n",
    "\n",
    "        # Reshape the outputs to match the shape of the labels\n",
    "        outputs = outputs.view(-1)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
